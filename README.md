# Zero Shot Picking  

ğŸš€ **Zero Shot Picking** is an AI-powered object retrieval system that enables a robotic arm to pick up objects from a container using only their names as input. This project demonstrates how vision-language models and advanced perception techniques can be used to perform zero-shot object identification and retrieval without prior training on specific objects.  

---
[Untitled_ Jul 10, 2023 12_52 PM.webm](https://github.com/user-attachments/assets/2437f024-9bb1-45e4-a712-f08c8fdce7cb)


https://github.com/user-attachments/assets/6c6fd186-bd49-4990-b7fa-cfa4e6a89c59




ğŸ”¹ **Video 1: Object Recognition**  
- A user inputs the name of an object.  
- The system captures an image of the container.  
- The model identifies and highlights the requested object in the captured image.  

ğŸ”¹ **Video 2: Robotic Arm Integration**  
- The system is connected to a robotic arm.  
- When a user inputs an objectâ€™s name, the robotic arm retrieves the object from the container based on the detected coordinates.  

---

## ğŸ›  **Technical Overview**  

ğŸ”¹ **Zero-Shot Object Detection**: The system leverages vision-language models to identify objects solely based on textual input, eliminating the need for prior object-specific training.  
ğŸ”¹ **Multi-Modal AI**: Combines **image processing** (e.g., SAM, GroundingDino) with **natural language understanding** to perform object selection.  
ğŸ”¹ **Robotic Arm Control**: Integrates with a robotic system to fetch the object and place it in the desired location.  
ğŸ”¹ **Computer Vision**: Uses advanced object detection techniques to locate and highlight objects in real-time.  

---

## âš ï¸ **Disclaimer**  
This repository does not include the source code due to confidentiality reasons. However, the provided videos showcase the capabilities and real-world application of the system.  

For inquiries or collaboration opportunities, feel free to reach out! ğŸš€  

---
